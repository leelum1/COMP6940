{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>COMP6940: Assignment 2</h1>\n",
    "<p>Kevan Lee Lum 816003573</p>\n",
    "<p>Due date: March 18 2018</p>\n",
    "<p>Windows: pyspark session started with pyspark --master local[2]</p>\n",
    "<p>Ubuntu: For some reason I need to set export PYSPARK_PYTHON=/usr/bin/python3 and export PYSPARK_DRIVER_PYTHON=python3 every time</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"border-top:2px solid black; border-bottom:2px solid black; padding:10px 0px 10px 0px; text-align:center;\">Task A</h2>\n",
    "<p>1. Convert the following sentence into a python tuple list of letters and the frequency of which each letter appears in the current word. Ignore all non-alpha numeric characters.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The quick brown fox jumps over the lazy dog and the fox was very happy\"\n",
    "\n",
    "tuplelist = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert all to lowercase to make things easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowersentence = sentence.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Add a whitespace at the end for fun. Actually its so that the last word is not forgotten. The whitespaces are used to determine the end of the word.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowersentence += \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('t', 1), ('e', 1), ('h', 1), ('i', 1), ('c', 1), ('u', 1), ('q', 1), ('k', 1), ('b', 1), ('o', 1), ('n', 1), ('r', 1), ('w', 1), ('o', 1), ('x', 1), ('f', 1), ('m', 1), ('s', 1), ('u', 1), ('j', 1), ('p', 1), ('o', 1), ('r', 1), ('v', 1), ('e', 1), ('t', 1), ('e', 1), ('h', 1), ('a', 1), ('l', 1), ('z', 1), ('y', 1), ('o', 1), ('d', 1), ('g', 1), ('n', 1), ('a', 1), ('d', 1), ('t', 1), ('e', 1), ('h', 1), ('o', 1), ('x', 1), ('f', 1), ('a', 1), ('s', 1), ('w', 1), ('y', 1), ('r', 1), ('v', 1), ('e', 1), ('h', 1), ('a', 1), ('y', 1), ('p', 2)]\n"
     ]
    }
   ],
   "source": [
    "currentworddict = {}\n",
    "for letter in lowersentence:\n",
    "    if letter == \" \":\n",
    "        for key in currentworddict.keys():\n",
    "            tuplelist.append((key, currentworddict[key]))\n",
    "        currentworddict = {}\n",
    "    else:\n",
    "        if letter in currentworddict.keys():\n",
    "            currentworddict[letter] += 1\n",
    "        else:\n",
    "            currentworddict[letter] = 1\n",
    "                             \n",
    "print(tuplelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Well that was fun. If there was a comma or period or something other than a letter in the sentence, the if statement could have read if letter not in some list of valid characters, do something.</p>\n",
    "<p>2. Create a PySpark Context</p>\n",
    "<p>What's a PySpark Context? From the docs, its the main entry point for Spark functionality, which represents the connection to a Spark cluster, and can be used to create RDD and broadcast variables on that cluster.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "sc = pyspark.SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>3. Convert the list of tuples into a PySpark RDD. RDD is a Resilient Distributed Dataset whch are dstributed collections of objects that can be cached in memory across cluster nodes. It represents an immutable, partitioned collection of elements that can be operated on in parallel. It will be interesting to compare the timing of these operations to those done without Spark.</p> \n",
    "\n",
    "<p>The parallelize function takes a Python structure to form an RDD. It is alledged</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(tuplelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>4. Using the methods of PySpark RDD display the letter count.</p>\n",
    "<p>The reduceByKey() method merges the values for each key using an associative and cummutative reduce function. In this case they are added.  The countByKey and reduceByKey methods also procude similar results but return dictionaries.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 4),\n",
       " ('b', 1),\n",
       " ('c', 1),\n",
       " ('d', 2),\n",
       " ('e', 5),\n",
       " ('f', 2),\n",
       " ('g', 1),\n",
       " ('h', 4),\n",
       " ('i', 1),\n",
       " ('j', 1),\n",
       " ('k', 1),\n",
       " ('l', 1),\n",
       " ('m', 1),\n",
       " ('n', 2),\n",
       " ('o', 5),\n",
       " ('p', 3),\n",
       " ('q', 1),\n",
       " ('r', 3),\n",
       " ('s', 2),\n",
       " ('t', 3),\n",
       " ('u', 2),\n",
       " ('v', 2),\n",
       " ('w', 2),\n",
       " ('x', 2),\n",
       " ('y', 3),\n",
       " ('z', 1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import add\n",
    "rdd.reduceByKey(add).sortByKey().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>5. Using the methods of PySpark RDD display the letter and number of times they appear in each word in the sentence.</p>\n",
    "<p>The groupByKey() method groups the values for each key in the RDD into a single sequence. Nice.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', [1, 1, 1, 1]),\n",
       " ('b', [1]),\n",
       " ('c', [1]),\n",
       " ('d', [1, 1]),\n",
       " ('e', [1, 1, 1, 1, 1]),\n",
       " ('f', [1, 1]),\n",
       " ('g', [1]),\n",
       " ('h', [1, 1, 1, 1]),\n",
       " ('i', [1]),\n",
       " ('j', [1]),\n",
       " ('k', [1]),\n",
       " ('l', [1]),\n",
       " ('m', [1]),\n",
       " ('n', [1, 1]),\n",
       " ('o', [1, 1, 1, 1, 1]),\n",
       " ('p', [1, 2]),\n",
       " ('q', [1]),\n",
       " ('r', [1, 1, 1]),\n",
       " ('s', [1, 1]),\n",
       " ('t', [1, 1, 1]),\n",
       " ('u', [1, 1]),\n",
       " ('v', [1, 1]),\n",
       " ('w', [1, 1]),\n",
       " ('x', [1, 1]),\n",
       " ('y', [1, 1, 1]),\n",
       " ('z', [1])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(rdd.groupByKey().mapValues(list).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"border-top:2px solid black; border-bottom:2px solid black; padding:10px 0px 10px 0px; text-align:center;\">Task B</h2>\n",
    "<p>1. Create a sql context from PySpark SQLContext.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row, SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Task 2\") \\\n",
    "    .config(\"spark.executor.memory\", \"1gb\") \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "sc2 = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>2. Load the Amazon Review Dataset into a PySpark RDD, ensure that each row is properly separated and the headers are matched to their respective columns.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = sc2.textFile('amazon_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',id,name,username',\n",
       " '0,AVpe7AsMilAPnD_xQ78G,Kindle Paperwhite,Cristina M',\n",
       " '1,AVpe7AsMilAPnD_xQ78G,Kindle Paperwhite,Ricky']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Oh problems. Each row appears to be one long string instead of separate columns. Since it is a csv, we split the columns at the \",\" using the map function.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = rdd2.map(lambda line: line.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['', 'id', 'name', 'username'],\n",
       " ['0', 'AVpe7AsMilAPnD_xQ78G', 'Kindle Paperwhite', 'Cristina M'],\n",
       " ['1', 'AVpe7AsMilAPnD_xQ78G', 'Kindle Paperwhite', 'Ricky']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Looks better now, although the lack of name on the first column might cause some problems</p>\n",
    "<p>3. Convert the rdd into a PySpark DataFrame.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id='id', no='', product='name', username='username'),\n",
       " Row(id='AVpe7AsMilAPnD_xQ78G', no='0', product='Kindle Paperwhite', username='Cristina M'),\n",
       " Row(id='AVpe7AsMilAPnD_xQ78G', no='1', product='Kindle Paperwhite', username='Ricky'),\n",
       " Row(id='AVpe7AsMilAPnD_xQ78G', no='2', product='Kindle Paperwhite', username='Tedd Gardiner'),\n",
       " Row(id='AVpe7AsMilAPnD_xQ78G', no='3', product='Kindle Paperwhite', username='Dougal')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = rdd2.map(lambda line: Row(no=line[0], \n",
    "                              id=line[1], \n",
    "                              product=line[2],\n",
    "                              username=line[3])).toDF()\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Looks good. The no. column appears to be a string but that's probably fine.</p>\n",
    "<p>4. Using the dataframe from question 3 show the top 20 bought products.</p>\n",
    "<p>The groupBy() method groups the DF using the 'name' column, to allow the use of the count agg function. The resulting DF is then sorted in descending order and the 20 most popular items are extracted using show(). The rows are not truncated by using False in the show method.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------+-----+\n",
      "|product                                                                                  |count|\n",
      "+-----------------------------------------------------------------------------------------+-----+\n",
      "|Amazon Tap - Alexa-Enabled Portable Bluetooth Speaker                                    |542  |\n",
      "|Amazon Fire TV                                                                           |166  |\n",
      "|Amazon Premium Headphones                                                                |133  |\n",
      "|Fire HD 6 Tablet                                                                         |87   |\n",
      "|\"Kindle Fire HDX 7\"\"\"                                                                    |53   |\n",
      "|\"Kindle Fire HDX 8.9\"\"\"                                                                  |43   |\n",
      "|\"Kindle Fire HD 7\"\"\"                                                                     |41   |\n",
      "|Kindle Paperwhite                                                                        |39   |\n",
      "|Certified Refurbished Amazon Fire TV (Previous Generation - 1st)                         |38   |\n",
      "|Kindle Keyboard                                                                          |32   |\n",
      "|All-New Amazon Fire 7 Tablet Case (7th Generation                                        |27   |\n",
      "|Kindle                                                                                   |20   |\n",
      "|Amazon 5W USB Official OEM Charger and Power Adapter for Fire Tablets and Kindle eReaders|19   |\n",
      "|All-New Amazon Fire HD 8 Tablet Case (7th Generation                                     |18   |\n",
      "|Replacement Remote for Amazon Fire TV Stick                                              |17   |\n",
      "|Echo Dot (2nd Generation) - Black                                                        |13   |\n",
      "|All-New Amazon Kid-Proof Case for Amazon Fire 7 Tablet (7th Generation                   |13   |\n",
      "|All-New Amazon Kid-Proof Case for Amazon Fire HD 8 Tablet (7th Generation                |12   |\n",
      "|Alexa Voice Remote for Amazon Fire TV and Fire TV Stick                                  |12   |\n",
      "|Moshi Anti-Glare No Bubble Screen Protector for the Fire Phone                           |12   |\n",
      "+-----------------------------------------------------------------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(['product']).count().sort(\"count\", ascending=False).show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>5. Using the dataframe from question 3  show the top 20 users and the products that they purchased.</p>\n",
    "<p>Can use the previous code to determine the 20 most frequent users</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------------------------------------------------------+-----+\n",
      "|username           |product                                                         |count|\n",
      "+-------------------+----------------------------------------------------------------+-----+\n",
      "|A. Younan          |Amazon Premium Headphones                                       |59   |\n",
      "|Andrew             |Amazon Premium Headphones                                       |43   |\n",
      "|Victor L.          |Amazon Premium Headphones                                       |30   |\n",
      "|William Hardin     |Fire HD 6 Tablet                                                |30   |\n",
      "|Mike W.            |Fire HD 6 Tablet                                                |29   |\n",
      "|Earthling1984      |Fire HD 6 Tablet                                                |28   |\n",
      "|B. Tarbuck         |\"Kindle Fire HDX 8.9\"\"\"                                         |16   |\n",
      "|William Hardin     |Amazon Fire TV                                                  |16   |\n",
      "|Mandy              |Amazon Fire TV                                                  |16   |\n",
      "|NF                 |\"Kindle Fire HDX 7\"\"\"                                           |15   |\n",
      "|Amazon Reviewer    |\"Kindle Fire HDX 8.9\"\"\"                                         |14   |\n",
      "|NF                 |\"Kindle Fire HD 7\"\"\"                                            |14   |\n",
      "|Amazon Reviewer    |\"Kindle Fire HDX 7\"\"\"                                           |13   |\n",
      "|William Hardin     |Certified Refurbished Amazon Fire TV (Previous Generation - 1st)|12   |\n",
      "|Michael Gallagher  |\"Kindle Fire HDX 7\"\"\"                                           |12   |\n",
      "|Dallas             |Amazon Fire TV                                                  |12   |\n",
      "|Gregory P. Baker   |Amazon Fire TV                                                  |11   |\n",
      "|MarkM              |\"Kindle Fire HD 7\"\"\"                                            |10   |\n",
      "|Mandy              |Certified Refurbished Amazon Fire TV (Previous Generation - 1st)|10   |\n",
      "|\"Things I Love Like|\"Kindle Fire HDX 8.9\"\"\"                                         |9    |\n",
      "+-------------------+----------------------------------------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(['username','product']).count().sort(\"count\", ascending=False).show(20, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>These answers are different from those in question 9. The answers here refer to people who have bought a single propduct multiple times. It possibly depends on how the question is interpreted. Oh well.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>6. Create a RDD of tuples from the dataframe from question 3 with only 2 columns ‘product’  and ‘username’ in that order.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(product='name', username='username'),\n",
       " Row(product='Kindle Paperwhite', username='Cristina M'),\n",
       " Row(product='Kindle Paperwhite', username='Ricky')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd3 = df['product', 'username'].rdd\n",
    "\n",
    "rdd3.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>7. Using methods from PySpark’s RDD object e.g. groupByKey, map, reduceByKey, derive the top 20 products.</p>\n",
    "<p>Assuming this would give the same results as question 4</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Amazon Tap - Alexa-Enabled Portable Bluetooth Speaker', 542),\n",
       " ('Amazon Fire TV', 166),\n",
       " ('Amazon Premium Headphones', 133),\n",
       " ('Fire HD 6 Tablet', 87),\n",
       " ('\"Kindle Fire HDX 7\"\"\"', 53),\n",
       " ('\"Kindle Fire HDX 8.9\"\"\"', 43),\n",
       " ('\"Kindle Fire HD 7\"\"\"', 41),\n",
       " ('Kindle Paperwhite', 39),\n",
       " ('Certified Refurbished Amazon Fire TV (Previous Generation - 1st)', 38),\n",
       " ('Kindle Keyboard', 32),\n",
       " ('All-New Amazon Fire 7 Tablet Case (7th Generation', 27),\n",
       " ('Kindle', 20),\n",
       " ('Amazon 5W USB Official OEM Charger and Power Adapter for Fire Tablets and Kindle eReaders',\n",
       "  19),\n",
       " ('All-New Amazon Fire HD 8 Tablet Case (7th Generation', 18),\n",
       " ('Replacement Remote for Amazon Fire TV Stick', 17),\n",
       " ('All-New Amazon Kid-Proof Case for Amazon Fire 7 Tablet (7th Generation',\n",
       "  13),\n",
       " ('Echo Dot (2nd Generation) - Black', 13),\n",
       " ('Alexa Voice Remote for Amazon Fire TV and Fire TV Stick', 12),\n",
       " ('Moshi Anti-Glare No Bubble Screen Protector for the Fire Phone', 12),\n",
       " ('Amazon Kindle Oasis Premium Leather Battery Cover - Walnut', 12)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd3.groupByKey().mapValues(len).sortBy(lambda x: x[1], ascending=False).take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Spent alot of time trying to make countByKey() work there.</p>\n",
    "<p>8. Create another RDD of tuples from the dataframe from question 3 with the columns ‘username’ and ‘product’ in that order.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(username='username', product='name'),\n",
       " Row(username='Cristina M', product='Kindle Paperwhite'),\n",
       " Row(username='Ricky', product='Kindle Paperwhite')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd4 = df['username', 'product'].rdd\n",
    "\n",
    "rdd4.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>9. Using methods from PySparks’s RDD object, produce the top 10 customers who purchased the most items. The top 10 list must show the usernames and a list of all the items each person bought. Each item should have an associated quantity value representing the amount of the item which was purchased by the customer.</p>\n",
    "<p>Create a custom mapping function to apply to each value</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A. Younan', ({'Amazon Premium Headphones': 59}, 59)),\n",
       " ('William Hardin',\n",
       "  ({'Amazon Fire TV': 16,\n",
       "    'Certified Refurbished Amazon Fire TV (Previous Generation - 1st)': 12,\n",
       "    'Fire HD 6 Tablet': 30},\n",
       "   58)),\n",
       " ('Andrew', ({'Amazon Premium Headphones': 43}, 43)),\n",
       " ('Victor L.', ({'Amazon Premium Headphones': 30}, 30)),\n",
       " ('NF', ({'\"Kindle Fire HD 7\"\"\"': 14, '\"Kindle Fire HDX 7\"\"\"': 15}, 29)),\n",
       " ('Mike W.', ({'Fire HD 6 Tablet': 29}, 29)),\n",
       " ('Earthling1984', ({'Fire HD 6 Tablet': 28}, 28)),\n",
       " ('Amazon Reviewer',\n",
       "  ({'\"Kindle Fire HDX 7\"\"\"': 13, '\"Kindle Fire HDX 8.9\"\"\"': 14}, 27)),\n",
       " ('Mandy',\n",
       "  ({'Amazon Fire TV': 16,\n",
       "    'Certified Refurbished Amazon Fire TV (Previous Generation - 1st)': 10},\n",
       "   26)),\n",
       " ('Amazon Customer',\n",
       "  ({'\"Kindle Fire HD 7\"\"\"': 1,\n",
       "    '\"Kindle Fire HDX 8.9\"\"\"': 1,\n",
       "    'Alexa Voice Remote for Amazon Fire TV and Fire TV Stick': 3,\n",
       "    'All-New Amazon Fire 7 Tablet Case (7th Generation': 2,\n",
       "    'All-New Amazon Kid-Proof Case for Amazon Fire 7 Tablet (7th Generation': 2,\n",
       "    'All-New Fire 7 Kids Edition Tablet': 1,\n",
       "    'All-New Fire HD 8 Kids Edition Tablet': 1,\n",
       "    'All-New Fire HD 8 Tablet with Alexa': 1,\n",
       "    'Amazon 5W USB Official OEM Charger and Power Adapter for Fire Tablets and Kindle eReaders': 1,\n",
       "    'Amazon Fire TV': 3,\n",
       "    'Certified Refurbished Echo Dot (2nd Generation) - Black': 1,\n",
       "    'Certified Refurbished Fire HD 10 Tablet': 1,\n",
       "    'Certified Refurbished Kindle E-reader - Black': 1,\n",
       "    'Kindle for Kids Bundle with the latest Kindle E-reader': 1,\n",
       "    'Moshi Anti-Glare No Bubble Screen Protector for the Fire Phone': 1,\n",
       "    'Replacement Remote for Amazon Fire TV Stick': 1},\n",
       "   22))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    y = list(x)\n",
    "    z = {}\n",
    "    for item in y:\n",
    "        if item in z.keys():\n",
    "            z[item] += 1\n",
    "        else:\n",
    "            z[item] = 1\n",
    "    return (z, len(x))\n",
    "\n",
    "rdd4.groupByKey().mapValues(f).sortBy(lambda x: x[1][1], ascending=False).take(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>I'm not sure if I did that the intended way. I know that the rdd had to be grouped by keys in order for the customers to be ordered. And I know that map Values had to be used to return the tuple of what was bought and the total count.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
