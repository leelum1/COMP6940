{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP 6940 Assignment #4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kevan Lee Lum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due Friday 13th April 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Classification and such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation, TruncatedSVD\n",
    "from string import punctuation\n",
    "from sklearn import svm\n",
    "from sklearn.utils import shuffle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from itertools import chain\n",
    "\n",
    "from sklearn.metrics import recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warm Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a Python function (from scratch) which takes the corpus and creates a vector representation of the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['Apple Orange Orange Apple', # [ 2.  0.  2.]\n",
    "  'Apple Banana Apple Banana', # [ 2.  2.  0.]\n",
    "  'Banana Apple Banana Banana Banana Apple', # [ 2.  4.  0.]\n",
    "  'Banana Orange Banana Banana Orange Banana', #[ 0.  4.  2.]\n",
    "  'Banana Apple Banana Banana Orange Banana'] # [ 1.  4.  1.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the bag of words model, we can take out the unique words in the corpus as a set, sort the set in alphabetical order, and then count the number of the times the words appear in each document. We can see that there are only three words to deal with, so it makes sense than an array of three items is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Apple', 'Banana', 'Orange']\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "for x in corpus:\n",
    "    y = x.split(\" \")\n",
    "    for z in y:\n",
    "        if z not in words:\n",
    "            words.append(z)\n",
    "sorted_words = sorted(words)\n",
    "print(sorted_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, now its time to count words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 0, 2], [2, 2, 0], [2, 4, 0], [0, 4, 2], [1, 4, 1]]\n"
     ]
    }
   ],
   "source": [
    "vector = []\n",
    "for doc in corpus:\n",
    "    doc_vector = []\n",
    "    split_doc = doc.split(\" \")\n",
    "    for word in sorted_words:\n",
    "        doc_vector.append(doc.count(word))\n",
    "    vector.append(doc_vector)\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like that worked. Apparently using the count () method is discouraged as it adds a loop for each word. Not good for the Big Oh. Some grouping and mapping methods may be more efficient, but this seems to be fine in this situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Data Organization "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is a collection of President Trump's speeches and viewer sentiment. Let's read in the data and check it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(836, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"MrTrumpSpeeches.csv\", sep=\"~\", encoding=\"ISO-8859-1\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>playlist</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>title</th>\n",
       "      <th>view_count</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>like_count</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>subtitles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2WTNSujhjk</td>\n",
       "      <td>Donald Trump Speeches &amp; Events</td>\n",
       "      <td>20160220</td>\n",
       "      <td>Live Stream: Donald Trump Victory Rally in Spa...</td>\n",
       "      <td>4057.0</td>\n",
       "      <td>4.259259</td>\n",
       "      <td>44.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>presidents of the United States mr. go   tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-64nfy6i58w</td>\n",
       "      <td>Donald Trump Speeches &amp; Events</td>\n",
       "      <td>20161107</td>\n",
       "      <td>LAST RALLY: Donald Trump FINAL CAMPAIGN Rally ...</td>\n",
       "      <td>47276.0</td>\n",
       "      <td>4.358025</td>\n",
       "      <td>952.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>it's now officially Tuesday November a   di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7Sp31hTxkU</td>\n",
       "      <td>Donald Trump Speeches &amp; Events</td>\n",
       "      <td>20160423</td>\n",
       "      <td>FULL SPEECH: Donald Trump Rally in Bridgeport,...</td>\n",
       "      <td>19966.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>220.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>you   [Music]   [Music]   [Music]   you   I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-byuyavcNI4</td>\n",
       "      <td>Donald Trump Speeches &amp; Events</td>\n",
       "      <td>20160617</td>\n",
       "      <td>Full Speech: Donald Trump Rally in Houston, Te...</td>\n",
       "      <td>15138.0</td>\n",
       "      <td>4.582491</td>\n",
       "      <td>266.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>we welcome stars and president   [Music]   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09BXh-AA72M</td>\n",
       "      <td>Donald Trump Speeches &amp; Events</td>\n",
       "      <td>20161105</td>\n",
       "      <td>Full Speech: Donald Trump Rally in Denver, Col...</td>\n",
       "      <td>8720.0</td>\n",
       "      <td>4.924731</td>\n",
       "      <td>365.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>you   thank you   [Music]   great people Gr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                        playlist  upload_date  \\\n",
       "0  -2WTNSujhjk  Donald Trump Speeches & Events     20160220   \n",
       "1  -64nfy6i58w  Donald Trump Speeches & Events     20161107   \n",
       "2  -7Sp31hTxkU  Donald Trump Speeches & Events     20160423   \n",
       "3  -byuyavcNI4  Donald Trump Speeches & Events     20160617   \n",
       "4  09BXh-AA72M  Donald Trump Speeches & Events     20161105   \n",
       "\n",
       "                                               title  view_count  \\\n",
       "0  Live Stream: Donald Trump Victory Rally in Spa...      4057.0   \n",
       "1  LAST RALLY: Donald Trump FINAL CAMPAIGN Rally ...     47276.0   \n",
       "2  FULL SPEECH: Donald Trump Rally in Bridgeport,...     19966.0   \n",
       "3  Full Speech: Donald Trump Rally in Houston, Te...     15138.0   \n",
       "4  Full Speech: Donald Trump Rally in Denver, Col...      8720.0   \n",
       "\n",
       "   average_rating  like_count  dislike_count  \\\n",
       "0        4.259259        44.0           10.0   \n",
       "1        4.358025       952.0          182.0   \n",
       "2        4.666667       220.0           20.0   \n",
       "3        4.582491       266.0           31.0   \n",
       "4        4.924731       365.0            7.0   \n",
       "\n",
       "                                           subtitles  \n",
       "0     presidents of the United States mr. go   tr...  \n",
       "1     it's now officially Tuesday November a   di...  \n",
       "2     you   [Music]   [Music]   [Music]   you   I...  \n",
       "3     we welcome stars and president   [Music]   ...  \n",
       "4     you   thank you   [Music]   great people Gr...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new column in the dataframe called 'sentiment'. Using the like and dislike counts, populate the new column with 0's and 1's where 0 refers to a negative sentiment and 1 refers to a positive sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numpy where method acts as an if statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>playlist</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>title</th>\n",
       "      <th>view_count</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>like_count</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>subtitles</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2WTNSujhjk</td>\n",
       "      <td>Donald Trump Speeches &amp; Events</td>\n",
       "      <td>20160220</td>\n",
       "      <td>Live Stream: Donald Trump Victory Rally in Spa...</td>\n",
       "      <td>4057.0</td>\n",
       "      <td>4.259259</td>\n",
       "      <td>44.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>presidents of the United States mr. go   tr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-64nfy6i58w</td>\n",
       "      <td>Donald Trump Speeches &amp; Events</td>\n",
       "      <td>20161107</td>\n",
       "      <td>LAST RALLY: Donald Trump FINAL CAMPAIGN Rally ...</td>\n",
       "      <td>47276.0</td>\n",
       "      <td>4.358025</td>\n",
       "      <td>952.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>it's now officially Tuesday November a   di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7Sp31hTxkU</td>\n",
       "      <td>Donald Trump Speeches &amp; Events</td>\n",
       "      <td>20160423</td>\n",
       "      <td>FULL SPEECH: Donald Trump Rally in Bridgeport,...</td>\n",
       "      <td>19966.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>220.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>you   [Music]   [Music]   [Music]   you   I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-byuyavcNI4</td>\n",
       "      <td>Donald Trump Speeches &amp; Events</td>\n",
       "      <td>20160617</td>\n",
       "      <td>Full Speech: Donald Trump Rally in Houston, Te...</td>\n",
       "      <td>15138.0</td>\n",
       "      <td>4.582491</td>\n",
       "      <td>266.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>we welcome stars and president   [Music]   ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09BXh-AA72M</td>\n",
       "      <td>Donald Trump Speeches &amp; Events</td>\n",
       "      <td>20161105</td>\n",
       "      <td>Full Speech: Donald Trump Rally in Denver, Col...</td>\n",
       "      <td>8720.0</td>\n",
       "      <td>4.924731</td>\n",
       "      <td>365.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>you   thank you   [Music]   great people Gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                        playlist  upload_date  \\\n",
       "0  -2WTNSujhjk  Donald Trump Speeches & Events     20160220   \n",
       "1  -64nfy6i58w  Donald Trump Speeches & Events     20161107   \n",
       "2  -7Sp31hTxkU  Donald Trump Speeches & Events     20160423   \n",
       "3  -byuyavcNI4  Donald Trump Speeches & Events     20160617   \n",
       "4  09BXh-AA72M  Donald Trump Speeches & Events     20161105   \n",
       "\n",
       "                                               title  view_count  \\\n",
       "0  Live Stream: Donald Trump Victory Rally in Spa...      4057.0   \n",
       "1  LAST RALLY: Donald Trump FINAL CAMPAIGN Rally ...     47276.0   \n",
       "2  FULL SPEECH: Donald Trump Rally in Bridgeport,...     19966.0   \n",
       "3  Full Speech: Donald Trump Rally in Houston, Te...     15138.0   \n",
       "4  Full Speech: Donald Trump Rally in Denver, Col...      8720.0   \n",
       "\n",
       "   average_rating  like_count  dislike_count  \\\n",
       "0        4.259259        44.0           10.0   \n",
       "1        4.358025       952.0          182.0   \n",
       "2        4.666667       220.0           20.0   \n",
       "3        4.582491       266.0           31.0   \n",
       "4        4.924731       365.0            7.0   \n",
       "\n",
       "                                           subtitles  sentiment  \n",
       "0     presidents of the United States mr. go   tr...          1  \n",
       "1     it's now officially Tuesday November a   di...          1  \n",
       "2     you   [Music]   [Music]   [Music]   you   I...          1  \n",
       "3     we welcome stars and president   [Music]   ...          1  \n",
       "4     you   thank you   [Music]   great people Gr...          1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'] = np.where(df['like_count'] > df['dislike_count'], 1, 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the subtitles data and store the cleaned text in a new column 'subtitle_clean'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to clean text data? By: \n",
    "<ul>\n",
    "    <li>Removing additional white spaces</li>\n",
    "    <li>Removing punctation</li>\n",
    "    <li>Removing common words (stop words)</li>\n",
    "</ul>\n",
    "Conveniently, Python has a punction operation to recognize punctuation characters. Split can be used to remove whitespace. Credit to <a href=\"http://adataanalyst.com/scikit-learn/countvectorizer-sklearn-example/\">this blog</a> for the function below, although its been modifed a bit to skip removing the stop words and return a string instead of a list. The stop words are removed by the classifier instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    return nopunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>playlist</th>\n",
       "      <th>upload_date</th>\n",
       "      <th>title</th>\n",
       "      <th>view_count</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>like_count</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>subtitles</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>subtitle_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2WTNSujhjk</td>\n",
       "      <td>Donald Trump Speeches &amp; Events</td>\n",
       "      <td>20160220</td>\n",
       "      <td>Live Stream: Donald Trump Victory Rally in Spa...</td>\n",
       "      <td>4057.0</td>\n",
       "      <td>4.259259</td>\n",
       "      <td>44.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>presidents of the United States mr. go   tr...</td>\n",
       "      <td>1</td>\n",
       "      <td>presidents of the United States mr go   tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-64nfy6i58w</td>\n",
       "      <td>Donald Trump Speeches &amp; Events</td>\n",
       "      <td>20161107</td>\n",
       "      <td>LAST RALLY: Donald Trump FINAL CAMPAIGN Rally ...</td>\n",
       "      <td>47276.0</td>\n",
       "      <td>4.358025</td>\n",
       "      <td>952.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>it's now officially Tuesday November a   di...</td>\n",
       "      <td>1</td>\n",
       "      <td>its now officially Tuesday November a   did...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-7Sp31hTxkU</td>\n",
       "      <td>Donald Trump Speeches &amp; Events</td>\n",
       "      <td>20160423</td>\n",
       "      <td>FULL SPEECH: Donald Trump Rally in Bridgeport,...</td>\n",
       "      <td>19966.0</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>220.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>you   [Music]   [Music]   [Music]   you   I...</td>\n",
       "      <td>1</td>\n",
       "      <td>you   Music   Music   Music   you   I   you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-byuyavcNI4</td>\n",
       "      <td>Donald Trump Speeches &amp; Events</td>\n",
       "      <td>20160617</td>\n",
       "      <td>Full Speech: Donald Trump Rally in Houston, Te...</td>\n",
       "      <td>15138.0</td>\n",
       "      <td>4.582491</td>\n",
       "      <td>266.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>we welcome stars and president   [Music]   ...</td>\n",
       "      <td>1</td>\n",
       "      <td>we welcome stars and president   Music   al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09BXh-AA72M</td>\n",
       "      <td>Donald Trump Speeches &amp; Events</td>\n",
       "      <td>20161105</td>\n",
       "      <td>Full Speech: Donald Trump Rally in Denver, Col...</td>\n",
       "      <td>8720.0</td>\n",
       "      <td>4.924731</td>\n",
       "      <td>365.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>you   thank you   [Music]   great people Gr...</td>\n",
       "      <td>1</td>\n",
       "      <td>you   thank you   Music   great people Gran...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                        playlist  upload_date  \\\n",
       "0  -2WTNSujhjk  Donald Trump Speeches & Events     20160220   \n",
       "1  -64nfy6i58w  Donald Trump Speeches & Events     20161107   \n",
       "2  -7Sp31hTxkU  Donald Trump Speeches & Events     20160423   \n",
       "3  -byuyavcNI4  Donald Trump Speeches & Events     20160617   \n",
       "4  09BXh-AA72M  Donald Trump Speeches & Events     20161105   \n",
       "\n",
       "                                               title  view_count  \\\n",
       "0  Live Stream: Donald Trump Victory Rally in Spa...      4057.0   \n",
       "1  LAST RALLY: Donald Trump FINAL CAMPAIGN Rally ...     47276.0   \n",
       "2  FULL SPEECH: Donald Trump Rally in Bridgeport,...     19966.0   \n",
       "3  Full Speech: Donald Trump Rally in Houston, Te...     15138.0   \n",
       "4  Full Speech: Donald Trump Rally in Denver, Col...      8720.0   \n",
       "\n",
       "   average_rating  like_count  dislike_count  \\\n",
       "0        4.259259        44.0           10.0   \n",
       "1        4.358025       952.0          182.0   \n",
       "2        4.666667       220.0           20.0   \n",
       "3        4.582491       266.0           31.0   \n",
       "4        4.924731       365.0            7.0   \n",
       "\n",
       "                                           subtitles  sentiment  \\\n",
       "0     presidents of the United States mr. go   tr...          1   \n",
       "1     it's now officially Tuesday November a   di...          1   \n",
       "2     you   [Music]   [Music]   [Music]   you   I...          1   \n",
       "3     we welcome stars and president   [Music]   ...          1   \n",
       "4     you   thank you   [Music]   great people Gr...          1   \n",
       "\n",
       "                                      subtitle_clean  \n",
       "0     presidents of the United States mr go   tra...  \n",
       "1     its now officially Tuesday November a   did...  \n",
       "2     you   Music   Music   Music   you   I   you...  \n",
       "3     we welcome stars and president   Music   al...  \n",
       "4     you   thank you   Music   great people Gran...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subtitle_clean'] = df['subtitles'].apply(text_process)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use TFIDFVectorizer and CountVectorizer to encode the clean subtitles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfidfVectorizer - Convert a collection of raw documents to a matrix of TF-IDF features. TF-IDF: Term Frequency - Inverse Document Frequency, is a word’s importance score in a document, among N documents. TF is the frequency of occurance of a word in a document, and IDF is the log(total no. of docs/no. of docs containing the word). Then multiply TF * IDF to obtain the final score. The higher the score the more important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer - Convert a collection of text documents to a matrix of token counts. Common words are removed using stop_words, since they will have no positive impact on the fitting of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to choose a metric to assess the performance of each classifier. The recall_score is intuitively the ability of the classifier to find all the positive samples. The F1 score can be interpreted as a weighted average of the precision and recall. So which to use? Why not both windows down and air condition?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is taken from some tutorial. Its been modified to return the metric scores to be plotted for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_fit(X, y, model,clf_model,coef_show=1):\n",
    "  \n",
    "    X_c = model.fit_transform(X)\n",
    "    print('# features: {}'.format(X_c.shape[1]))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_c, y, random_state=0)\n",
    "    print('# train records: {}'.format(X_train.shape[0]))\n",
    "    print('# test records: {}'.format(X_test.shape[0]))\n",
    "    clf = clf_model.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    print ('Model Recall: {}'.format(round(recall,3)))\n",
    "    f1 = f1_score(y_test,y_pred)\n",
    "    print ('Model F1 Score: {}'.format(round(f1,3)))\n",
    "    \n",
    "\n",
    "    if coef_show == 1: \n",
    "        w = model.get_feature_names()\n",
    "        coef = clf.coef_.tolist()[0]\n",
    "        coeff_df = pd.DataFrame({'Word' : w, 'Coefficient' : coef})\n",
    "        coeff_df = coeff_df.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\n",
    "        print('')\n",
    "        print('-Top 20 positive-')\n",
    "        print(coeff_df.head(20).to_string(index=False))\n",
    "        print('')\n",
    "        print('-Top 20 negative-')        \n",
    "        print(coeff_df.tail(20).to_string(index=False))\n",
    "        \n",
    "    return (recall, f1)\n",
    "\n",
    "# X is the training data\n",
    "# y is testing data\n",
    "# model is the text represented as a vector\n",
    "# clf_model is the classification algorithm\n",
    "# coe_show indicates if to show the top pos and neg coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data is the cleaned subtitles, and the testing data is the sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       presidents of the United States mr go   tra...\n",
       "1       its now officially Tuesday November a   did...\n",
       "2       you   Music   Music   Music   you   I   you...\n",
       "3       we welcome stars and president   Music   al...\n",
       "4       you   thank you   Music   great people Gran...\n",
       "Name: subtitle_clean, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['subtitle_clean']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['sentiment']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression model on word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 23629\n",
      "# train records: 627\n",
      "# test records: 209\n",
      "Model Recall: 0.953\n",
      "Model F1 Score: 0.943\n",
      "\n",
      "-Top 20 positive-\n",
      "Coefficient       Word\n",
      "   0.418233     little\n",
      "   0.411612      going\n",
      "   0.363002       came\n",
      "   0.339053  president\n",
      "   0.304206       wait\n",
      "   0.288401        new\n",
      "   0.279933       long\n",
      "   0.276159    justice\n",
      "   0.267035      north\n",
      "   0.265828        god\n",
      "   0.259288  americans\n",
      "   0.255128      pence\n",
      "   0.240390    nuclear\n",
      "   0.227764  confirmed\n",
      "   0.227140      today\n",
      "   0.224004     cities\n",
      "   0.222549      bless\n",
      "   0.222277    hillary\n",
      "   0.221957      women\n",
      "   0.221763      korea\n",
      "\n",
      "-Top 20 negative-\n",
      "Coefficient        Word\n",
      "  -0.239089     ratings\n",
      "  -0.242630        jeff\n",
      "  -0.253473   yesterday\n",
      "  -0.254015      arnold\n",
      "  -0.260961   everybody\n",
      "  -0.264122     blocked\n",
      "  -0.264472        said\n",
      "  -0.269445    business\n",
      "  -0.270934    applause\n",
      "  -0.272569        weve\n",
      "  -0.275084      strong\n",
      "  -0.278458     meeting\n",
      "  -0.281599     protect\n",
      "  -0.283521   agreement\n",
      "  -0.287290        fake\n",
      "  -0.308583    horrible\n",
      "  -0.309311  presidents\n",
      "  -0.313510         sir\n",
      "  -0.354945       ideas\n",
      "  -0.449612       hello\n"
     ]
    }
   ],
   "source": [
    "log_count = text_fit(X, y, c, LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression model on TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 23629\n",
      "# train records: 627\n",
      "# test records: 209\n",
      "Model Recall: 1.0\n",
      "Model F1 Score: 0.958\n",
      "\n",
      "-Top 20 positive-\n",
      "Coefficient       Word\n",
      "   1.741625      going\n",
      "   0.761915       know\n",
      "   0.693937     people\n",
      "   0.627620    hillary\n",
      "   0.580165    country\n",
      "   0.578576    clinton\n",
      "   0.554167      thank\n",
      "   0.543111     united\n",
      "   0.500533     states\n",
      "   0.493527  president\n",
      "   0.434680      world\n",
      "   0.425319        new\n",
      "   0.421729      trump\n",
      "   0.419451      north\n",
      "   0.410995      great\n",
      "   0.387584       tell\n",
      "   0.384891     donald\n",
      "   0.378265         mr\n",
      "   0.373507     theyre\n",
      "   0.359639     mexico\n",
      "\n",
      "-Top 20 negative-\n",
      "Coefficient        Word\n",
      "  -0.378882         tax\n",
      "  -0.401759        erie\n",
      "  -0.471568  interviews\n",
      "  -0.484208       ideas\n",
      "  -0.502754        fake\n",
      "  -0.512962        fans\n",
      "  -0.528058       hello\n",
      "  -0.579475      latest\n",
      "  -0.594912   subscribe\n",
      "  -0.599776     youtube\n",
      "  -0.602037    checking\n",
      "  -0.603438      button\n",
      "  -0.614299     channel\n",
      "  -0.634956     digital\n",
      "  -0.638808    clicking\n",
      "  -0.639413       click\n",
      "  -0.640570  exclusives\n",
      "  -0.640570  highlights\n",
      "  -0.654581      videos\n",
      "  -0.852130      thanks\n"
     ]
    }
   ],
   "source": [
    "log_tfidf = text_fit(X, y, tfidf, LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression model on TFIDF + ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 405881\n",
      "# train records: 627\n",
      "# test records: 209\n",
      "Model Recall: 1.0\n",
      "Model F1 Score: 0.958\n",
      "\n",
      "-Top 20 positive-\n",
      "Coefficient             Word\n",
      "   1.521005            going\n",
      "   0.766765             know\n",
      "   0.765657           people\n",
      "   0.570653          country\n",
      "   0.525122            thank\n",
      "   0.519925          hillary\n",
      "   0.511571            great\n",
      "   0.471236          clinton\n",
      "   0.401380             want\n",
      "   0.394668           united\n",
      "   0.385708             dont\n",
      "   0.377202    united states\n",
      "   0.375166           theyre\n",
      "   0.374617           states\n",
      "   0.347659  hillary clinton\n",
      "   0.346103            world\n",
      "   0.344010        president\n",
      "   0.334713            right\n",
      "   0.333193            trump\n",
      "   0.329588             like\n",
      "\n",
      "-Top 20 negative-\n",
      "Coefficient                Word\n",
      "  -0.457356             channel\n",
      "  -0.457372        click videos\n",
      "  -0.457372     thanks checking\n",
      "  -0.457372        videos watch\n",
      "  -0.464663               click\n",
      "  -0.470787             digital\n",
      "  -0.473559            clicking\n",
      "  -0.473614     youtube channel\n",
      "  -0.474933        button click\n",
      "  -0.474933   channel subscribe\n",
      "  -0.474933    checking youtube\n",
      "  -0.474933     clicking button\n",
      "  -0.474933  digital exclusives\n",
      "  -0.474933          exclusives\n",
      "  -0.474933          highlights\n",
      "  -0.474933  highlights digital\n",
      "  -0.474933  subscribe clicking\n",
      "  -0.474933        watch latest\n",
      "  -0.475258              videos\n",
      "  -0.644985              thanks\n"
     ]
    }
   ],
   "source": [
    "tfidf_n = TfidfVectorizer(ngram_range=(1,2),stop_words = 'english')\n",
    "log_tfidf_n = text_fit(X, y, tfidf_n, LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine model on word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# features: 23629\n",
      "# train records: 627\n",
      "# test records: 209\n",
      "Model Recall: 0.938\n",
      "Model F1 Score: 0.935\n",
      "\n",
      "-Top 20 positive-\n",
      "Coefficient        Word\n",
      "   0.132116      little\n",
      "   0.128390        wait\n",
      "   0.125842       pence\n",
      "   0.116261      values\n",
      "   0.112171       going\n",
      "   0.107061     justice\n",
      "   0.105175        came\n",
      "   0.089476   president\n",
      "   0.083913   confirmed\n",
      "   0.083593        safe\n",
      "   0.081917        long\n",
      "   0.079468       north\n",
      "   0.078884       today\n",
      "   0.076631   represent\n",
      "   0.076388      choose\n",
      "   0.074595     michael\n",
      "   0.072121     affront\n",
      "   0.071215  absolutely\n",
      "   0.070599     richard\n",
      "   0.070452     talking\n",
      "\n",
      "-Top 20 negative-\n",
      "Coefficient        Word\n",
      "  -0.085198       judge\n",
      "  -0.089666  presidents\n",
      "  -0.090233     protect\n",
      "  -0.090295        fake\n",
      "  -0.090609   agreement\n",
      "  -0.090874       music\n",
      "  -0.090934  government\n",
      "  -0.094004   everybody\n",
      "  -0.095548     meeting\n",
      "  -0.096328     version\n",
      "  -0.096606    horrible\n",
      "  -0.098107     ratings\n",
      "  -0.098405        weve\n",
      "  -0.102572      arnold\n",
      "  -0.104884     blocked\n",
      "  -0.107544    applause\n",
      "  -0.121477         sir\n",
      "  -0.122879       ideas\n",
      "  -0.126210       ready\n",
      "  -0.161174       hello\n"
     ]
    }
   ],
   "source": [
    "svm_count = text_fit(X, y, c, svm.LinearSVC())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine model on TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_tfidf = text_fit(X, y, tfidf, svm.LinearSVC())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine model on TFIDF + ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_tfidf_n = text_fit(X, y, tfidf_n, svm.LinearSVC())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a bar graph showing the performance of each of the experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to gather the scores and matplotlib them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = [log_count[0], log_tfidf[0], log_tfidf_n[0], svm_count[0], svm_tfidf[0], svm_tfidf_n[0]]\n",
    "labels = ['log_count', 'log_tfidf', 'log_tfidf_n', 'svm_count', 'svm_tfidf', 'svm_tfidf_n']\n",
    "sns.barplot(labels, recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the recall scores are very similar for all classifier. However, it can be inferred that the tfidf classfiers are more accurate than the word count classifier. Let's check the f1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = [log_count[1], log_tfidf[1], log_tfidf_n[1], svm_count[1], svm_tfidf[1], svm_tfidf_n[1]]\n",
    "sns.barplot(labels, f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores are even closer in this one and so more difficult to read. The same inferences can be made though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic modelling is about finding words in a documents that map to a similar concept. In other words, What is he talking about? which can be difficult regarding who is speaking. This is useful in reducing the dimensions of the document and helps with classification and modelling. I really hope we don't have to know the background to these methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below was copied from the tutorial, with the second half commented out to not print out the entire documents because they are long, and returning a list of lists of clusters to create the wordclouds from. This was difficult to comprehend. H is the topics found by the model, and this function prints the top words that correspond to each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(H, W, feature_names, documents, no_top_words, no_top_documents):\n",
    "    all_topics = []\n",
    "    for topic_idx, topic in enumerate(H):\n",
    "        print(\"Topic %d:\" % (topic_idx))\n",
    "        topics = [feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "        all_topics.append(topics)\n",
    "        print(\" \".join(topics)) \n",
    "        \n",
    "#         top_doc_indices = np.argsort( W[:,topic_idx] )[::-1][0:no_top_documents]\n",
    "#         for doc_index in top_doc_indices:\n",
    "#             print(documents[doc_index])\n",
    "    return all_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = list(X)\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picking the amount of topics is important as choosing too little may group unrelated words together, and picking too much will also have the same result as the model is fishing for words. I used an iterative process to see what made the most sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_topics = 3\n",
    "no_top_words = 10\n",
    "no_top_documents = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non Negative Matrix Factorization finds two non-negative matrices (W, H) whose product approximates the non-negative matrix X/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NMF is able to use tf-idf. The documents are transformed into matrices in this step\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(documents)     #Vectorizing the documents\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()    #All the words used in the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMF(n_components=no_topics, random_state=1, alpha=.1, l1_ratio=.5, init='nndsvd').fit(tfidf)\n",
    "nmf_W = nmf_model.transform(tfidf)    #Transform the data X according to the fitted NMF model\n",
    "nmf_H = nmf_model.components_    #Factorization matrix, sometimes called ‘dictionary’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NMF Topics \\n\\n\")\n",
    "nmf_clusters = display_topics(nmf_H, nmf_W, tfidf_feature_names, documents, no_top_words, no_top_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(documents)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components=no_topics, max_iter=5, learning_method='online', \n",
    "                                      learning_offset=50.,random_state=0).fit(tf)\n",
    "lda_W = lda_model.transform(tf)\n",
    "lda_H = lda_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nLDA Topics \\n\\n\")\n",
    "lda_clusters = display_topics(lda_H, lda_W, tf_feature_names, documents, no_top_words, no_top_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic 0:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_model = TruncatedSVD(n_components=no_topics, n_iter=7, random_state=42).fit(tf)\n",
    "lsi_W = lsi_model.transform(tf)\n",
    "lsi_H = lsi_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nLSI Topics \\n\\n\")\n",
    "svd_clusters = display_topics(lsi_H, lsi_W, tf_feature_names, documents, no_top_words, no_top_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose the clusters obtained from a topic model algorithm from above and plot a word cloud for each of the clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text visualization can help to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since NMF produced the most clear topics, wordclouds will be produced for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in nmf_clusters:\n",
    "    print(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wordcloud module is used to plot the wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size']=12                #10 \n",
    "plt.rcParams['figure.subplot.bottom']=.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function method was copied from the tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cloud(data):\n",
    "    wordcloud = WordCloud(\n",
    "              background_color='white',\n",
    "              max_words=200,\n",
    "              max_font_size=40, \n",
    "              random_state=42\n",
    "             ).generate(str(data))\n",
    "    return wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in nmf_clusters:\n",
    "    wordcloud = print_cloud(cluster)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't look very exciting with just 10 words in it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
